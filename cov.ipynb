{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-karen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install DgL-KE and/or pykeen to compute knowledge graph embeddings. \n",
    "!pip3 install torch\n",
    "!pip3 install pandas\n",
    "!pip3 install numpy\n",
    "!pip install pykeen==1.4.0\n",
    "!pip install networkx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import gzip, os, csv\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import pykeen\n",
    "from pykeen.datasets.base import SingleTabbedDataset\n",
    "from pykeen.pipeline import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and quickly process data (creation of knowledgegraph look here: https://github.com/DJRavinszkha/covid_kges)\n",
    "df = pd.read_csv('https://zenodo.org/record/4783052/files/KG_FINAL.tsv?download=1', sep=\"\\t\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and quickly process data (creation of knowledgegraph look here: https://github.com/DJRavinszkha/covid_kges)\n",
    "df = pd.read_csv('https://zenodo.org/record/4783052/files/KG_FINAL.tsv?download=1', sep=\"\\t\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi = df2.get_group('ddi-interactor-in')\n",
    "C = df2.get_group('C')\n",
    "J = df2.get_group('J')\n",
    "Mp = df2.get_group('Mp')\n",
    "Pa = df2.get_group('Pa')\n",
    "Pr = df2.get_group('Pr')\n",
    "Sa = df2.get_group('Sa')\n",
    "T = df2.get_group('T')\n",
    "L = df2.get_group('L')\n",
    "D = df2.get_group('D')\n",
    "G = df2.get_group('G')\n",
    "Md = df2.get_group('Md')\n",
    "Te = df2.get_group('Te')\n",
    "U = df2.get_group('U')\n",
    "Ud = df2.get_group('Ud')\n",
    "X = df2.get_group('X')\n",
    "Y = df2.get_group('Y')\n",
    "Apos = df2.get_group('A+')\n",
    "Aneg = df2.get_group('A-')\n",
    "B = df2.get_group('B')\n",
    "E = df2.get_group('E')\n",
    "Epos = df2.get_group('E+')\n",
    "Eneg = df2.get_group('E-')\n",
    "K = df2.get_group('K')\n",
    "N = df2.get_group('N')\n",
    "O = df2.get_group('O')\n",
    "Z = df2.get_group('Z')\n",
    "H = df2.get_group('H')\n",
    "I = df2.get_group('I')\n",
    "Q = df2.get_group('Q')\n",
    "Rg = df2.get_group('Rg')\n",
    "Vpos = df2.get_group('V+')\n",
    "W = df2.get_group('W')\n",
    "interacts = df2.get_group('interacts_with')\n",
    "MI0915 = df2.get_group('MI:0915')\n",
    "MI0407 = df2.get_group('MI:0407')\n",
    "MI0914 = df2.get_group('MI:0914')\n",
    "MI0217 = df2.get_group('MI:0217')\n",
    "MI0195 = df2.get_group('MI:0195')\n",
    "MI0570 = df2.get_group('MI:0570')\n",
    "MI0414 = df2.get_group('MI:0414')\n",
    "MI0194 = df2.get_group('MI:0194')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-ivory",
   "metadata": {},
   "outputs": [],
   "source": [
    "MI = pd.concat([MI0915, MI0407, MI0914, MI0217, MI0195,\n",
    "               MI0570, MI0414, MI0194])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into 0.9 training set and 0.05 test/valid set\n",
    "def splitter(triples):\n",
    "    triples = df.values.tolist()\n",
    "    num_triples = len(triples)\n",
    "\n",
    "    seed = np.arange(num_triples)\n",
    "    np.random.shuffle(seed)\n",
    "\n",
    "    train_cnt = int(num_triples * 0.9)\n",
    "    valid_cnt = int(num_triples * 0.05)\n",
    "    train_set = seed[:train_cnt]\n",
    "    train_set = train_set.tolist()\n",
    "    valid_set = seed[train_cnt:train_cnt+valid_cnt].tolist()\n",
    "    test_set = seed[train_cnt+valid_cnt:].tolist()\n",
    "    return(train_set, test_set, valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-acrobat",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ddi_train, ddi_test, ddi_valid) = splitter(ddi)\n",
    "(C_train, C_test, C_valid) = splitter(C)\n",
    "(J_train, J_test, J_valid) = splitter(J)\n",
    "(Mp_train, Mp_test, Mp_valid) = splitter(Mp)\n",
    "(Pa_train, Pa_test, Pa_valid) = splitter(Pa)\n",
    "(Pr_train, Pr_test, Pr_valid) = splitter(Pr)\n",
    "(Sa_train, Sa_test, Sa_valid) = splitter(Sa)\n",
    "(T_train, T_test, T_valid) = splitter(T)\n",
    "(L_train, L_test, L_valid) = splitter(L)\n",
    "(D_train, D_test, D_valid) = splitter(D)\n",
    "(G_train, G_test, G_valid) = splitter(G)\n",
    "(Md_train, Md_test, Md_valid) = splitter(Md)\n",
    "(Te_train, Te_test, Te_valid) = splitter(Te)\n",
    "(U_train, U_test, U_valid) = splitter(U)\n",
    "(Ud_train, Ud_test, Ud_valid) = splitter(Ud)\n",
    "(X_train, X_test, X_valid) = splitter(X)\n",
    "(Y_train, Y_test, Y_valid) = splitter(Y)\n",
    "(Apos_train, Apos_test, Apos_valid) = splitter(Apos)\n",
    "(Aneg_train, Aneg_test, Aneg_valid) = splitter(Aneg)\n",
    "(B_train, B_test, B_valid) = splitter(B)\n",
    "(E_train, E_test, E_valid) = splitter(E)\n",
    "(Epos_train, Epos_test, Epos_valid) = splitter(Epos)\n",
    "(Eneg_train, Eneg_test, Eneg_valid) = splitter(Eneg)\n",
    "(K_train, K_test, K_valid) = splitter(L)\n",
    "(N_train, N_test, N_valid) = splitter(N)\n",
    "(O_train, O_test, O_valid) = splitter(O)\n",
    "(Z_train, Z_test, Z_valid) = splitter(Z)\n",
    "(H_train, H_test, H_valid) = splitter(H)\n",
    "(I_train, I_test, I_valid) = splitter(I)\n",
    "(Q_train, Q_test, Q_valid) = splitter(Q)\n",
    "(Rg_train, Rg_test, Rg_valid) = splitter(Rg)\n",
    "(Vpos_train, Vpos_test, Vpos_valid) = splitter(Vpos)\n",
    "(W_train, W_test, W_valid) = splitter(W)\n",
    "(interacts_train, interacts_test, interacts_valid) = splitter(interacts)\n",
    "(MI_train, MI_test, MI_valid) = splitter(MI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = (ddi_train + C_train + J_train + Mp_train +\n",
    "             Pa_train + Pr_train + Sa_train + T_train +\n",
    "             L_train + D_train + G_train + Md_train +\n",
    "             Te_train + U_train + Ud_train + X_train +\n",
    "             Y_train + Apos_train + Aneg_train +\n",
    "             B_train + E_train + Epos_train + Eneg_train +\n",
    "             K_train + N_train + O_train + Z_train +\n",
    "             H_train + I_train + Q_train + Rg_train +\n",
    "             Vpos_train + W_train + interacts_train + MI_train)\n",
    "\n",
    "test_set = (ddi_test + C_test + J_test + Mp_test +\n",
    "            Pa_test + Pr_test + Sa_test + T_test +\n",
    "            L_test + D_test + G_test + Md_test +\n",
    "            Te_test + U_test + Ud_test + X_test +\n",
    "            Y_test + Apos_test + Aneg_test +\n",
    "            B_test + E_test + Epos_test + Eneg_test +\n",
    "            K_test + N_test + O_test + Z_test +\n",
    "            H_test + I_test + Q_test + Rg_test +\n",
    "            Vpos_test + W_test + interacts_test + MI_test)\n",
    "\n",
    "valid_set = (ddi_valid + C_valid + J_valid + Mp_valid +\n",
    "             Pa_valid + Pr_valid + Sa_valid + T_valid +\n",
    "             L_valid + D_valid + G_valid + Md_valid +\n",
    "             Te_valid + U_valid + Ud_valid + X_valid +\n",
    "             Y_valid + Apos_valid + Aneg_valid +\n",
    "             B_valid + E_valid + Epos_valid + Eneg_valid +\n",
    "             K_valid + N_valid + O_valid + Z_valid +\n",
    "             H_valid + I_valid + Q_valid + Rg_valid +\n",
    "             Vpos_valid + W_valid + interacts_valid + MI_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-scratch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write train, test and validate sets\n",
    "with open(\"train/kg_train.tsv\", 'w+') as f:\n",
    "    for idx in train_set:\n",
    "        f.writelines(\"{}\\t{}\\t{}\\n\".format(triples[idx][0],\n",
    "                                           triples[idx][1],\n",
    "                                           triples[idx][2]))\n",
    "with open(\"train/kg_valid.tsv\", 'w+') as f:\n",
    "    for idx in valid_set:\n",
    "        f.writelines(\"{}\\t{}\\t{}\\n\".format(triples[idx][0],\n",
    "                                           triples[idx][1],\n",
    "                                           triples[idx][2]))\n",
    "with open(\"train/kg_test.tsv\", 'w+') as f:\n",
    "    for idx in test_set:\n",
    "        f.writelines(\"{}\\t{}\\t{}\\n\".format(triples[idx][0],\n",
    "                                           triples[idx][1],\n",
    "                                           triples[idx][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train/kg_train.tsv', sep = '\\t')\n",
    "test = pd.read_csv('train/kg_test.tsv', sep = '\\t')\n",
    "valid = pd.read_csv('train/kg_valid.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a model\n",
    "print(\"Load Training Data\")\n",
    "from pykeen.triples import TriplesFactory\n",
    "train_data = TriplesFactory.from_path('train/kg_train.tsv')\n",
    "\n",
    "print(\"Initialise TransR\")\n",
    "from pykeen.models import TransR\n",
    "transr = TransR(triples_factory=train_data)\n",
    "\n",
    "print(\"Initialise Adam's Optimiser\")\n",
    "# Pick an optimizer from Torch\n",
    "from torch.optim import Adam\n",
    "optimizer = Adam(params=transr.get_grad_params())\n",
    "\n",
    "print(\"Initialise LCWA Training Approach\")\n",
    "# Pick a training approach (sLCWA or LCWA)\n",
    "from pykeen.training import LCWATrainingLoop\n",
    "training_loop = LCWATrainingLoop(model=transr, optimizer=optimizer)\n",
    "\n",
    "print(\"Train TransR\")\n",
    "# Train like Cristiano Ronaldo\n",
    "training_loop.train(num_epochs=16000, batch_size=1024)\n",
    "\n",
    "print(\"Initialise RankBased Evaluator\")\n",
    "# Pick an evaluator\n",
    "from pykeen.evaluation import RankBasedEvaluator\n",
    "evaluator = RankBasedEvaluator()\n",
    "\n",
    "print(\"Evaluate TransR\")\n",
    "# Evaluate\n",
    "results = evaluator.evaluate(transr, 'train/kg_test.tsv', batch_size=1024)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
